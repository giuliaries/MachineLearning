{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic-Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuliaries/MachineLearning/blob/main/Titanic_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-poGIWvsk0Y"
      },
      "source": [
        "[Giulia Santoiemma](mailto:giulia.santoiemma@studenti.unipd.it) 2004775<br/>\n",
        "Machine Learning<br/> \n",
        "Master Degree in Computer Science<br/>\n",
        "19 November 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kqbrsT18u7-"
      },
      "source": [
        "# Import libraries\n",
        "from google.colab import files\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.svm import SVC\n",
        "from tabulate import tabulate\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7ZCF0HS2wK8"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "This is the [Titanic dataset by Kaggle](https://www.kaggle.com/c/titanic).\n",
        "\n",
        "I have used machine learning to create a model that predicts which passengers survived the Titanic shipwreck."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "duDROuK8Ysh8",
        "outputId": "40736042-ca3d-4d33-f4d9-f7f41a34ace2"
      },
      "source": [
        "# Import the train.csv file from Titanic dataset by Kaggle\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-237e9534-188b-41ef-a34a-4672c7a46d26\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-237e9534-188b-41ef-a34a-4672c7a46d26\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.csv to train (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LUp6VKwj_FN5",
        "outputId": "358ed12d-574c-4b3c-d8ab-7153961cf8cf"
      },
      "source": [
        "# Read the CSV and show the first and last rows of the dataset\n",
        "# titanic = pd.read_csv(io.BytesIO(uploaded['train.csv']))\n",
        "titanic = pd.read_csv(\"./train.csv\")\n",
        "titanic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0              1         0       3  ...   7.2500   NaN         S\n",
              "1              2         1       1  ...  71.2833   C85         C\n",
              "2              3         1       3  ...   7.9250   NaN         S\n",
              "3              4         1       1  ...  53.1000  C123         S\n",
              "4              5         0       3  ...   8.0500   NaN         S\n",
              "..           ...       ...     ...  ...      ...   ...       ...\n",
              "886          887         0       2  ...  13.0000   NaN         S\n",
              "887          888         1       1  ...  30.0000   B42         S\n",
              "888          889         0       3  ...  23.4500   NaN         S\n",
              "889          890         1       1  ...  30.0000  C148         C\n",
              "890          891         0       3  ...   7.7500   NaN         Q\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvKjAoTZZZwa",
        "outputId": "ef9f6135-b4b6-4316-f693-38b5fcc4cc1c"
      },
      "source": [
        "print(\"Example:\", titanic.shape[0])\n",
        "print(\"Features:\", titanic.shape[1])\n",
        "print(\"\\nExample per each feature:\")\n",
        "print(titanic.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example: 891\n",
            "Features: 12\n",
            "\n",
            "Example per each feature:\n",
            "PassengerId    891\n",
            "Survived       891\n",
            "Pclass         891\n",
            "Name           891\n",
            "Sex            891\n",
            "Age            714\n",
            "SibSp          891\n",
            "Parch          891\n",
            "Ticket         891\n",
            "Fare           891\n",
            "Cabin          204\n",
            "Embarked       889\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9UkQsf5E4-v"
      },
      "source": [
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th><b>Variable</b></th>\n",
        "      <th><b>Definition</b></th>\n",
        "      <th><b>Type</b></th>\n",
        "      <th><b>Key</b></th>\n",
        "      <th><b># Missing Values</b></th>\n",
        "      <th><b>Relevant</b></th>\n",
        "    </tr>\n",
        "  <thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>PassengerId</td>\n",
        "      <td>Identification for each passenger within the dataset</td>\n",
        "      <td>Progressive integer</td>\n",
        "      <td></td>\n",
        "      <td>-</td>\n",
        "      <td>No</td>\n",
        "    <tr>\n",
        "      <td>Survived</td>\n",
        "      <td>The passenger survived the shipwreck or not</td>\n",
        "      <td>Binary number</td>\n",
        "      <td>0 = No,<br/>1 = Yes</td>\n",
        "      <td>-</td>\n",
        "      <td>-</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Pclass</td>\n",
        "      <td>Class of the ticket purchased by the passenger</td>\n",
        "      <td>Integer</td>\n",
        "      <td>1 = 1st,<br/>2 = 2nd,<br/>3 = 3rd</td>\n",
        "      <td>-</td>\n",
        "      <td>Yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Name</td>\n",
        "      <td>Full name of the passenger</td>\n",
        "      <td>Alphanumeric string</td>\n",
        "      <td></td>\n",
        "      <td>-</td>\n",
        "      <td>No</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Sex</td>\n",
        "      <td>Passenger's sex</td>\n",
        "      <td>Alphanumeric string</td>\n",
        "      <td>male,<br/>female</td>\n",
        "      <td>-</td>\n",
        "      <td>Yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Age</td>\n",
        "      <td>Passenger's age in years</td>\n",
        "      <td>Decimal number<br/>(decimal to indicate uncertain ages<br/>or ages less than one year of life)</td>\n",
        "      <td></td>\n",
        "      <td>177</td>\n",
        "      <td>Yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Sibsp</td>\n",
        "      <td># of siblings / spouses aboard the Titanic</td>\n",
        "      <td>Integer</td>\n",
        "      <td></td>\n",
        "      <td>-</td>\n",
        "      <td>Yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Parch</td>\n",
        "      <td># of parents / children aboard the Titanic</td>\n",
        "      <td>Integer</td>\n",
        "      <td></td>\n",
        "      <td>-</td>\n",
        "      <td>Yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Ticket</td>\n",
        "      <td>Number of the ticket purchased by the passenger</td>\n",
        "      <td>Alphanumeric string</td>\n",
        "      <td></td>\n",
        "      <td>-</td>\n",
        "      <td>No</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Fare</td>\n",
        "      <td>Fare paid by the passenger for the purchase of the ticket</td>\n",
        "      <td>Decimal</td>\n",
        "      <td></td>\n",
        "      <td>-</td>\n",
        "      <td>Yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Cabin</td>\n",
        "      <td>Cabin number in which the passenger was</td>\n",
        "      <td>Alphanumeric string</td>\n",
        "      <td></td>\n",
        "      <td>687</td>\n",
        "      <td>No</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Embarked</td>\n",
        "      <td>Port of Embarkation</td>\n",
        "      <td>Alphanumeric string</td>\n",
        "      <td>C = Cherbourg,<br/>Q = Queenstown,<br/>S = Southampton</td>\n",
        "      <td>2</td>\n",
        "      <td>Yes</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv2rikOui3hy"
      },
      "source": [
        "In the table above we can see the description of the Titanic dataset.\n",
        "\n",
        "The dataset is made up of 891 distinct examples and each of them is represented by 12 different features.\n",
        "\n",
        "I have identified what I believe are the characteristics relevant to a passenger's survival expectancy.\n",
        "\n",
        "The `Survived` feature is not included in the evaluation because it is used as target value.\n",
        "\n",
        "Then I have executed 4 different preprocesses, combining the features relevant to me, to see the effectiveness of the predictions as the features change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtbrEEWRZ0uV"
      },
      "source": [
        "## Missing Values\n",
        "\n",
        "To use the dataset with learning models in order to make predictions and evaluate their performance, it is necessary that each example has all the characteristics evaluated.\n",
        "\n",
        "Therefore I have filled in the characteristics which contain missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESGu8gEcGit4"
      },
      "source": [
        "# Feature \"Age\"\n",
        "# If the value is missing, the average of all the other examples has been entered\n",
        "titanic['Age'] = SimpleImputer(missing_values=np.NaN, strategy='mean').fit_transform(np.array(titanic['Age'].values)[:, np.newaxis])\n",
        "\n",
        "# Feature \"Embarked\"\n",
        "# If the value is missing, the most frequent value has been entered\n",
        "titanic['Embarked'] = SimpleImputer(missing_values=np.NaN, strategy='most_frequent').fit_transform(np.array(titanic['Embarked'].values)[:, np.newaxis])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U_ZAyllZ3BU"
      },
      "source": [
        "## Encoding\n",
        "\n",
        "To get better performance from the learning models, it is preferable that the input features are all of the same type.\n",
        "\n",
        "Therefore I have codified the string features into numeric features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4iNn_KZzBeW"
      },
      "source": [
        "# Encoding of the \"Sex\" feature with OneHot Encoding\n",
        "# Encode categorical features as a one-hot numeric array.\n",
        "# The features are encoded using a one-hot (aka ‘one-of-K’ or ‘dummy’) encoding scheme. \n",
        "# This creates a binary column for each category and returns a sparse matrix or dense array (depending on the sparse parameter)\n",
        "titanic['Sex'] = OneHotEncoder(categories='auto').fit_transform(np.array(titanic['Sex'].values)[:, np.newaxis]).toarray()\n",
        "\n",
        "# Encoding of the \"Embarked\" feature with Ordinal Encoding\n",
        "# The features are converted to ordinal integers. \n",
        "titanic['Embarked'] = OrdinalEncoder(categories='auto').fit_transform(np.array(titanic['Embarked'].values)[:, np.newaxis])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC10HoIu3vXf"
      },
      "source": [
        "## Study of correlations among variables\n",
        "\n",
        "I have selected the target feature and defined the 4 datasets used for training the prediction models.\n",
        "\n",
        "I have then divided each dataset into training sets and test sets, to train and evaluate learning models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYDEZpeu4Q7f"
      },
      "source": [
        "# Target value to evaluate performance\n",
        "target = titanic['Survived']\n",
        "\n",
        "# Number of dataset used\n",
        "dataset_number = 5\n",
        "\n",
        "headers = {}\n",
        "dataset = {}\n",
        "i = 0\n",
        "\n",
        "# Personal features\n",
        "headers[i] = \"Personal\"\n",
        "dataset[i] = titanic.filter(['Sex','Age'], axis=1)\n",
        "i += 1\n",
        "\n",
        "# Personal features and features about family\n",
        "headers[i] = \"Personal + Family\"\n",
        "dataset[i] = titanic.filter(['Sex','Age','SibSp','Parch'], axis=1)\n",
        "i += 1\n",
        "\n",
        "# Personal features and features about the ticket\n",
        "headers[i] = \"Personal + Ticket\"\n",
        "dataset[i] = titanic.filter(['Sex','Age','Pclass','Embarked','Fare'], axis=1)\n",
        "i += 1\n",
        "\n",
        "# Personal features and features about family and ticket\n",
        "headers[i] = \"Personal + Family + Ticket\"\n",
        "dataset[i] = titanic.filter(['Sex','Age','SibSp','Parch','Pclass','Embarked','Fare'], axis=1)\n",
        "i += 1\n",
        "\n",
        "# Features about the ticket\n",
        "headers[i] = \"Ticket\"\n",
        "dataset[i] = titanic.filter(['Pclass','Embarked','Fare'], axis=1)\n",
        "\n",
        "# Split each datasets into random train and test subsets\n",
        "X_train, X_test, y_train, y_test = {}, {}, {}, {}\n",
        "for i in range(dataset_number):\n",
        "  X_train[i], X_test[i], y_train[i], y_test[i] = train_test_split(dataset[i], target, test_size=0.3, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M10vkNBZ3xhR"
      },
      "source": [
        "## Choice of the predictor and Model Selection\n",
        "\n",
        "To evaluate the quality of the 4 preprocessing strategies, I have trained 3 different learning algorithms on each training set:\n",
        "\n",
        "* Support Vector Machine\n",
        "* K Nearest Neighbors\n",
        "* Neural Network\n",
        "\n",
        "Then I verified how the quality of the prediction changes, depending on the model and preprocessing used.\n",
        "\n",
        "To compare the performance I have used 3 metrics:\n",
        "\n",
        "* accuracy\n",
        "* precision\n",
        "* recall\n",
        "\n",
        "Each metric, for each example, evaluates the model classification compared to the predicted target value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C-M8trUu_em",
        "outputId": "e0ac8dfd-226e-43f2-acef-12626f6b5d7c"
      },
      "source": [
        "# Name of the Classifiers\n",
        "classifier = [\"Support Vector Machine\", \"K-Nearest Neighbors\", \"Neural Network\"]\n",
        "# Set string lenght to have the tabulate with the same width\n",
        "for key, value in enumerate(classifier):\n",
        "  classifier[key] = value.ljust(22)\n",
        "\n",
        "# Foreach Classifier\n",
        "for k, model in enumerate([SVC(), KNeighborsClassifier(), MLPClassifier()]):\n",
        "\n",
        "  report = [[\"Accuracy\"], [\"Precision\"], [\"Recall\"]]\n",
        "\n",
        "  # Foreach dataset\n",
        "  for i in range(dataset_number):\n",
        "\n",
        "    # Fit the current model according to the given training dataset\n",
        "    model.fit(X_train[i], y_train[i])\n",
        "\n",
        "    # Predict the classification for the provided data (the test set)\n",
        "    y_pred = model.predict(X_test[i])\n",
        "\n",
        "    # Accuracy classification score.\n",
        "    # In multilabel classification, this function computes subset accuracy: \n",
        "    # the set of labels predicted for a sample must exactly match the corresponding set of labels in y_test.\n",
        "    # If normalized, the best value is 1 and the worst value is 0.\n",
        "    report[0].append(accuracy_score(y_test[i], y_pred))\n",
        "\n",
        "    # Compute the precision.\n",
        "    # The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. \n",
        "    # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
        "    # The best value is 1 and the worst value is 0.\n",
        "    report[1].append(precision_score(y_test[i], y_pred))\n",
        "\n",
        "    # Compute the recall.\n",
        "    # The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. \n",
        "    # The recall is intuitively the ability of the classifier to find all the positive samples.\n",
        "    # The best value is 1 and the worst value is 0.\n",
        "    report[2].append(recall_score(y_test[i], y_pred))\n",
        "\n",
        "  # Show the results for the current Classifier\n",
        "  print(tabulate(report, headers=[classifier[k]] + list(headers.values()), tablefmt=\"rst\"), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================  ==========  ===================  ===================  ============================  ========\n",
            "Support Vector Machine      Personal    Personal + Family    Personal + Ticket    Personal + Family + Ticket    Ticket\n",
            "========================  ==========  ===================  ===================  ============================  ========\n",
            "Accuracy                   0.567164             0.578358              0.641791                      0.652985  0.626866\n",
            "Precision                  0.470588             0.571429              0.666667                      0.703704  0.682927\n",
            "Recall                     0.0695652            0.0695652             0.330435                      0.330435  0.243478\n",
            "========================  ==========  ===================  ===================  ============================  ======== \n",
            "\n",
            "========================  ==========  ===================  ===================  ============================  ========\n",
            "K-Nearest Neighbors         Personal    Personal + Family    Personal + Ticket    Personal + Family + Ticket    Ticket\n",
            "========================  ==========  ===================  ===================  ============================  ========\n",
            "Accuracy                    0.731343             0.716418             0.716418                      0.705224  0.645522\n",
            "Precision                   0.721649             0.729412             0.724138                      0.7       0.638889\n",
            "Recall                      0.608696             0.53913              0.547826                      0.547826  0.4\n",
            "========================  ==========  ===================  ===================  ============================  ======== \n",
            "\n",
            "========================  ==========  ===================  ===================  ============================  ========\n",
            "Neural Network              Personal    Personal + Family    Personal + Ticket    Personal + Family + Ticket    Ticket\n",
            "========================  ==========  ===================  ===================  ============================  ========\n",
            "Accuracy                    0.757463             0.768657             0.757463                      0.768657  0.641791\n",
            "Precision                   0.745098             0.784946             0.735849                      0.784946  0.620253\n",
            "Recall                      0.66087              0.634783             0.678261                      0.634783  0.426087\n",
            "========================  ==========  ===================  ===================  ============================  ======== \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-3DMp9H3LbO"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "As we can see from the outputs, SVM has better results as the number of relevant features increases, but it never has too high values.\n",
        "\n",
        "The other two models, on the other hand, have better and constant results as the number of functions increases.\n",
        "The only dataset in which they have worse values is the one with only travel and ticket data.\n",
        "\n",
        "So we can infer that personal features and features about the number of family members are important.\n",
        "This makes us understand that the removal of relevant features affects the goodness of the forecast.\n"
      ]
    }
  ]
}